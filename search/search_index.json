{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Coming Soon \ud83d\udd1c","title":"Home"},{"location":"#coming-soon","text":"","title":"Coming Soon \ud83d\udd1c"},{"location":"gsoc/community-bonding/","text":"Community Bonding The Community Bonding period lasted from May 20 to June 12, and it was a lot of fun and fruitful. I had the wonderful opportunity to meet my mentor Sayam Kumar at an in-person meetup in Delhi on the first day of my community bonding periods. It was a fantastic day for me as we discussed about the project, took some photos \ud83d\udcf8, and had a lot of fun. \ud83c\udf89 Unfortunately, my end-semester exams began on the 25th of May and lasted until the 13th of June, so I did not have enough time to interact with the community in this period. However I managed to find some time to participate in the PyMC Developer hackathon. I worked on the issue #5581 with Maxim Kochurov and had the opportunity to meet the amazing PyMC community members, developers, and contributors. While working on this issue, I learned a lot about Variational Inference , how tests works, and more about the PyMC code base. PyMC Developer Hackathon Nothing is going to stop this crew from releasing PyMC 4.0! Join the fun at https://t.co/HjPB9ZsZPZ pic.twitter.com/56uATxmR9i \u2014 PyMC Developers (@pymc_devs) June 2, 2022 GSoCers Meet In the final week of the community bonding period Larry Dong hosted a Google meet, where I met all of the GSoC selected participants for this year. We got to know each other, talked about our projects, our interests, and had a lot of fun. What I learned? I didn't have much time to learn about the projects because of my end-semester exam, so I spent the last week of community bonding period by reading Aesara documentation . I learned about Aesara syntax, followed the beginner's Tutorial , and created some small programmes to become more acquainted with Aesara. Then I learned about Aesara Ops , Graph Structures , and Aesara's Broadcasting features. What is coming up next? The Coding Period has already begun, and I am behind on my proposal timeline due to my university exam, but this week I will collect all of the Ops from Aesara that are used in multivariate implementations and will discuss the project's implementation with my mentor. In addition, I am reading more about the various statistical distributions to gain a better understanding of them. In my next blog, I'll discuss project implementation. Thank you very much.\ud83d\ude0a With \ud83d\udc96 Purna.","title":"Community Bonding"},{"location":"gsoc/community-bonding/#community-bonding","text":"The Community Bonding period lasted from May 20 to June 12, and it was a lot of fun and fruitful. I had the wonderful opportunity to meet my mentor Sayam Kumar at an in-person meetup in Delhi on the first day of my community bonding periods. It was a fantastic day for me as we discussed about the project, took some photos \ud83d\udcf8, and had a lot of fun. \ud83c\udf89 Unfortunately, my end-semester exams began on the 25th of May and lasted until the 13th of June, so I did not have enough time to interact with the community in this period. However I managed to find some time to participate in the PyMC Developer hackathon. I worked on the issue #5581 with Maxim Kochurov and had the opportunity to meet the amazing PyMC community members, developers, and contributors. While working on this issue, I learned a lot about Variational Inference , how tests works, and more about the PyMC code base.","title":"Community Bonding"},{"location":"gsoc/community-bonding/#pymc-developer-hackathon","text":"Nothing is going to stop this crew from releasing PyMC 4.0! Join the fun at https://t.co/HjPB9ZsZPZ pic.twitter.com/56uATxmR9i \u2014 PyMC Developers (@pymc_devs) June 2, 2022","title":"PyMC Developer Hackathon"},{"location":"gsoc/community-bonding/#gsocers-meet","text":"In the final week of the community bonding period Larry Dong hosted a Google meet, where I met all of the GSoC selected participants for this year. We got to know each other, talked about our projects, our interests, and had a lot of fun.","title":"GSoCers Meet"},{"location":"gsoc/community-bonding/#what-i-learned","text":"I didn't have much time to learn about the projects because of my end-semester exam, so I spent the last week of community bonding period by reading Aesara documentation . I learned about Aesara syntax, followed the beginner's Tutorial , and created some small programmes to become more acquainted with Aesara. Then I learned about Aesara Ops , Graph Structures , and Aesara's Broadcasting features.","title":"What I learned?"},{"location":"gsoc/community-bonding/#what-is-coming-up-next","text":"The Coding Period has already begun, and I am behind on my proposal timeline due to my university exam, but this week I will collect all of the Ops from Aesara that are used in multivariate implementations and will discuss the project's implementation with my mentor. In addition, I am reading more about the various statistical distributions to gain a better understanding of them. In my next blog, I'll discuss project implementation. Thank you very much.\ud83d\ude0a With \ud83d\udc96 Purna.","title":"What is coming up next?"},{"location":"gsoc/gsoc-2022-with-pymc/","text":"GSoC'22 with PyMC I'm happy to share that my Google Summer of Code proposal has been accepted by PyMC under the NumFOCUS umbrella. I'd like to express my gratitude to my mentors Sayam Kumar and Ricardo Vieira , as well as the entire PyMC community, for providing this opportunity. This summer, I'm looking forward to expanding my skills and contributing to the PyMC library. I'd like to thank all the PyMC members for their assistance, from merging my first PR to reviewing my proposal. The Dashboard for my GSoC project can be viewed here About the Project My project is to Increase Support for Batched Multivariate Distributions , several multivariate distributions in PyMC , such as MvNormal , MvStudentT , and others, are constrained to working with 2D inputs and do not function with arbitrarily batched dimensions. The project's goal is to improve multivariate distribution support, making it possible to work with batched data (> 2D) in a vectorized manner. My First Task My initial goal for this project is to Investigate how Random Variables are implemented in v4. Collect all Aesara Ops that are utilised in multivariate distribution implementations. Expand the Ops to operate with more than 2D inputs. Update any/all test cases relating to these Ops and multivariate distributions. What\u2019s next? I will be posting about my GSoC experiences on a weekly basis. Thank you. \ud83d\ude0a With \ud83d\udc96 Purna.","title":"GSoC'22 with PyMC"},{"location":"gsoc/gsoc-2022-with-pymc/#gsoc22-with-pymc","text":"I'm happy to share that my Google Summer of Code proposal has been accepted by PyMC under the NumFOCUS umbrella. I'd like to express my gratitude to my mentors Sayam Kumar and Ricardo Vieira , as well as the entire PyMC community, for providing this opportunity. This summer, I'm looking forward to expanding my skills and contributing to the PyMC library. I'd like to thank all the PyMC members for their assistance, from merging my first PR to reviewing my proposal. The Dashboard for my GSoC project can be viewed here","title":"GSoC'22 with PyMC"},{"location":"gsoc/gsoc-2022-with-pymc/#about-the-project","text":"My project is to Increase Support for Batched Multivariate Distributions , several multivariate distributions in PyMC , such as MvNormal , MvStudentT , and others, are constrained to working with 2D inputs and do not function with arbitrarily batched dimensions. The project's goal is to improve multivariate distribution support, making it possible to work with batched data (> 2D) in a vectorized manner.","title":"About the Project"},{"location":"gsoc/gsoc-2022-with-pymc/#my-first-task","text":"My initial goal for this project is to Investigate how Random Variables are implemented in v4. Collect all Aesara Ops that are utilised in multivariate distribution implementations. Expand the Ops to operate with more than 2D inputs. Update any/all test cases relating to these Ops and multivariate distributions.","title":"My First Task"},{"location":"gsoc/gsoc-2022-with-pymc/#whats-next","text":"I will be posting about my GSoC experiences on a weekly basis. Thank you. \ud83d\ude0a With \ud83d\udc96 Purna.","title":"What\u2019s next?"},{"location":"gsoc/week-1-2-into-GSoC/","text":"Week 1-2 into GSoC The coding period has finally begun! My mentor, Sayam Kumar , and I have agreed to hold weekly progress calls to discuss the project's progress and what steps we should take next. The Week begins with this phone call. We decided to split the project into two parts because it involves two libraries. Aesara PyMC The first step was to collect Aesara's Op , which is used in Multivariate Distributions. Before we continue, allow me to introduce you to Aesara and its Op . Though I am still learning, I have some knowledge of Op from the end of community bonding. Aesara The best description is the one taken straight from the GitHub repository and Read the Docs: Aesara is a Python library that lets you define, optimize, and evaluate mathematical expressions, especially ones involving multi-dimensional arrays (e.g. numpy.ndarrays). Using Aesara it is possible to attain speeds rivaling hand-crafted C implementations for problems involving large amounts of data. Aesara\u2019s compiler applies many optimizations of varying complexity to these symbolic expressions. Working with Aesara Here is an example of how to use Aesara. It doesn\u2019t show off many of its features, but it illustrates concretely what Aesara is. import aesara from aesara import tensor as at # declare two symbolic floating-point scalars a = at.dscalar() b = at.dscalar() # create a simple expression c = a + b # convert the expression into a callable object that takes `(a, b)` # values as input and computes a value for `c` f = aesara.function([a, b], c) # bind 1.5 to 'a', 2.5 to 'b', and evaluate 'c' assert 4.0 == f(1.5, 2.5) The example above was taken straight from the frontpage of Aesara. Here, a , b and c are tensor variables of type TensorVariable which do not have a value associated. Aesara is not a programming language in the normal sense because you write a program in Python that builds expressions for Aesara. Still it is like a programming language in the sense that you have to declare variables a and b and give their types, build expressions graphs using those variables, compile the expression graphs into functions that can be used for computation. It is good to think of aesara.function() as the interface to a compiler which builds a callable object from a purely symbolic graph. One of Aesara\u2019s most important features is that aesara.function() can optimize a graph and even compile some or all of it into native machine instructions. Getting started with Project To begin, in order to keep track of our progress, my mentor and I created a list of Action Items, which can be found here . We chose to begin with cholesky decomposition because it has been used in many distributions. I had no idea how to begin implementing an Op in Aesara because it was all new to me. However, I would like to express my gratitude to my Mentor and Luciano Paz for their invaluable assistance. Luciano Paz has already begun work on this Op, and he has provided me with his implementation for reference. Looking at his code gave me a good idea of how to write a new Op in Aesara. In order to validate my understanding of Op, I created a new Op and wrote some tests, which are listed below. After testing all of the operations with batch data, we identified the following operations to work on: solve cholesky det eigh matrix_inverse So I'm hoping to complete these Ops by the end of phase 1 of GSoC. I am grateful to my mentor for his constant guidance and to the pymc-devs community for its encouragement. Thank you for reading!","title":"Week 1-2 into GSoC"},{"location":"gsoc/week-1-2-into-GSoC/#week-1-2-into-gsoc","text":"The coding period has finally begun! My mentor, Sayam Kumar , and I have agreed to hold weekly progress calls to discuss the project's progress and what steps we should take next. The Week begins with this phone call. We decided to split the project into two parts because it involves two libraries. Aesara PyMC The first step was to collect Aesara's Op , which is used in Multivariate Distributions. Before we continue, allow me to introduce you to Aesara and its Op . Though I am still learning, I have some knowledge of Op from the end of community bonding.","title":"Week 1-2 into GSoC"},{"location":"gsoc/week-1-2-into-GSoC/#aesara","text":"The best description is the one taken straight from the GitHub repository and Read the Docs: Aesara is a Python library that lets you define, optimize, and evaluate mathematical expressions, especially ones involving multi-dimensional arrays (e.g. numpy.ndarrays). Using Aesara it is possible to attain speeds rivaling hand-crafted C implementations for problems involving large amounts of data. Aesara\u2019s compiler applies many optimizations of varying complexity to these symbolic expressions.","title":"Aesara"},{"location":"gsoc/week-1-2-into-GSoC/#working-with-aesara","text":"Here is an example of how to use Aesara. It doesn\u2019t show off many of its features, but it illustrates concretely what Aesara is. import aesara from aesara import tensor as at # declare two symbolic floating-point scalars a = at.dscalar() b = at.dscalar() # create a simple expression c = a + b # convert the expression into a callable object that takes `(a, b)` # values as input and computes a value for `c` f = aesara.function([a, b], c) # bind 1.5 to 'a', 2.5 to 'b', and evaluate 'c' assert 4.0 == f(1.5, 2.5) The example above was taken straight from the frontpage of Aesara. Here, a , b and c are tensor variables of type TensorVariable which do not have a value associated. Aesara is not a programming language in the normal sense because you write a program in Python that builds expressions for Aesara. Still it is like a programming language in the sense that you have to declare variables a and b and give their types, build expressions graphs using those variables, compile the expression graphs into functions that can be used for computation. It is good to think of aesara.function() as the interface to a compiler which builds a callable object from a purely symbolic graph. One of Aesara\u2019s most important features is that aesara.function() can optimize a graph and even compile some or all of it into native machine instructions.","title":"Working with Aesara"},{"location":"gsoc/week-1-2-into-GSoC/#getting-started-with-project","text":"To begin, in order to keep track of our progress, my mentor and I created a list of Action Items, which can be found here . We chose to begin with cholesky decomposition because it has been used in many distributions. I had no idea how to begin implementing an Op in Aesara because it was all new to me. However, I would like to express my gratitude to my Mentor and Luciano Paz for their invaluable assistance. Luciano Paz has already begun work on this Op, and he has provided me with his implementation for reference. Looking at his code gave me a good idea of how to write a new Op in Aesara. In order to validate my understanding of Op, I created a new Op and wrote some tests, which are listed below. After testing all of the operations with batch data, we identified the following operations to work on: solve cholesky det eigh matrix_inverse So I'm hoping to complete these Ops by the end of phase 1 of GSoC. I am grateful to my mentor for his constant guidance and to the pymc-devs community for its encouragement. Thank you for reading!","title":"Getting started with Project"},{"location":"gsoc/week-3-4-into-GSoC/","text":"Week 3-4 into GSoC Following up on my work from weeks 1 and 2, I began working on Cholesky decomposition with the assistance of my mentor and Luciano Paz . However, because the Cholesky op is dependent on some small op tril and triu , which do not support batched data, we decided to fix these op first. After 3-4 days of debugging and understanding the code, I finally came up with a solution, and this week I created my first PR #1026 . Work done in this PR: After conducting numerous experiments with tril and triu , I discovered that in order to work with batched data, we must use the last two dimensions of the batched data. Now that this minor issue has been resolved, tril and triu can work with batch data. Finally, I cleaned up the code, added some examples, and fixed the docstring. I finished my first PR to be merged after writing the test cases for the new feature:) This PR boosts my confidence for future work; I now have a solid understanding of Aesara and its Op. What next ? So the next step is to finish implementing Cholesky Op. However, we have two options here: we can use Scipy to compute Cholesky decomposition, but Scipy is limited to 2d data only, or we can use vectorization to work with batched data. The second option is to use Numpy to compute the Cholesky decomposition, which supports batched data but is slightly slower than Scipy. So we must experiment with these two methods to determine which is the best to implement in the Aesara library. So, within the next week, I will devise a strategy for implementing the Cholesky in Apsara. I am thankful to my mentor for his constant guidance and pymc-devs for being such a supportive community. Thank you for reading!","title":"Week 3-4 into GSoC"},{"location":"gsoc/week-3-4-into-GSoC/#week-3-4-into-gsoc","text":"Following up on my work from weeks 1 and 2, I began working on Cholesky decomposition with the assistance of my mentor and Luciano Paz . However, because the Cholesky op is dependent on some small op tril and triu , which do not support batched data, we decided to fix these op first. After 3-4 days of debugging and understanding the code, I finally came up with a solution, and this week I created my first PR #1026 .","title":"Week 3-4 into GSoC"},{"location":"gsoc/week-3-4-into-GSoC/#work-done-in-this-pr","text":"After conducting numerous experiments with tril and triu , I discovered that in order to work with batched data, we must use the last two dimensions of the batched data. Now that this minor issue has been resolved, tril and triu can work with batch data. Finally, I cleaned up the code, added some examples, and fixed the docstring. I finished my first PR to be merged after writing the test cases for the new feature:) This PR boosts my confidence for future work; I now have a solid understanding of Aesara and its Op.","title":"Work done in this PR:"},{"location":"gsoc/week-3-4-into-GSoC/#what-next","text":"So the next step is to finish implementing Cholesky Op. However, we have two options here: we can use Scipy to compute Cholesky decomposition, but Scipy is limited to 2d data only, or we can use vectorization to work with batched data. The second option is to use Numpy to compute the Cholesky decomposition, which supports batched data but is slightly slower than Scipy. So we must experiment with these two methods to determine which is the best to implement in the Aesara library. So, within the next week, I will devise a strategy for implementing the Cholesky in Apsara. I am thankful to my mentor for his constant guidance and pymc-devs for being such a supportive community. Thank you for reading!","title":"What next ?"},{"location":"gsoc/week-5-6-into-GSoC/","text":"Week 5-6 into GSoC This week I spent a lot of time experimenting with Numpy and Scipy's performance. I've made two notebooks, one for small batches of data and one for large amounts of data. I recorded the time it took Numpy and Scipy to compute the Cholesky decomposition and obtained the following result: Experiment - 1 (for small data) Experiment - 2 (for large data) To summarize I got the bellow 2 graphs: Numpy vs Scipy for Small Dataset Numpy vs Scipy for Large Dataset As we can see from these two graphs, Numpy outperforms Python with a reasonable dataset, so we chose the Numpy implementation. I implemented the Solve and Cholesky in Aesara with the help of my mentor, and we are now working on resolving some grad issues. I owe my mentor a huge debt of gratitude. He is really amiable and helpful. He is always willing to assist and has clarified all of my doubts for me, even when I ask him dumb things in Slack. He spent a lot of time debugging the code and came up with an easy fix; in fact, he taught me how to debug. He's the one who first showed me how to use the Python Debugger (PDB). Without my Mentor, I can't image how my GSoC experience would be, Sayam Kumar . I am grateful to my mentor for his ongoing advice and to the pymc-devs community for being so encouraging.","title":"Week 5-6 into GSoC"},{"location":"gsoc/week-5-6-into-GSoC/#week-5-6-into-gsoc","text":"This week I spent a lot of time experimenting with Numpy and Scipy's performance. I've made two notebooks, one for small batches of data and one for large amounts of data. I recorded the time it took Numpy and Scipy to compute the Cholesky decomposition and obtained the following result:","title":"Week 5-6 into GSoC"},{"location":"gsoc/week-5-6-into-GSoC/#experiment-1-for-small-data","text":"","title":"Experiment - 1 (for small data)"},{"location":"gsoc/week-5-6-into-GSoC/#experiment-2-for-large-data","text":"To summarize I got the bellow 2 graphs: Numpy vs Scipy for Small Dataset Numpy vs Scipy for Large Dataset As we can see from these two graphs, Numpy outperforms Python with a reasonable dataset, so we chose the Numpy implementation. I implemented the Solve and Cholesky in Aesara with the help of my mentor, and we are now working on resolving some grad issues. I owe my mentor a huge debt of gratitude. He is really amiable and helpful. He is always willing to assist and has clarified all of my doubts for me, even when I ask him dumb things in Slack. He spent a lot of time debugging the code and came up with an easy fix; in fact, he taught me how to debug. He's the one who first showed me how to use the Python Debugger (PDB). Without my Mentor, I can't image how my GSoC experience would be, Sayam Kumar . I am grateful to my mentor for his ongoing advice and to the pymc-devs community for being so encouraging.","title":"Experiment - 2 (for large data)"},{"location":"gsoc/work-summary/","text":"Google Summer of Code'22 Highlights with PyMC This post is intended to summarise the work completed during the GSoC coding period. About the project \ud83d\udea9 Several multivariate distributions in PyMC, such as MvNormal, MvStudentT, and others, are constrained to working with 2D inputs and do not function with arbitrarily batched dimensions. The project's goal was to improve multivariate distribution support, making it possible to work with batched data (>2D) in a vectorized manner. Community Bounding Period \ud83e\udd1d This was a super interesting period. I got to know about many PyMC core developers through slack. Due to my university exam I was quite occupied but I managed to spent some time learning about the basics of Bayesian statistics, RandomVariable, Aesara. I took part in PyMC Developer Hackathon which gave me opprtunity of meet with PyMC core developer in video call and learned a lot of things about PyMC. I started working on some good first issue and by the help of PyMC team I was able to merger the PR #5806 The most difficult part for me was understanding the Aesara, how the symbolic variale works and how to implement a new Ops. Month - 1\ufe0f\u20e3: The coding period began on June 13, and my goal for this period was to list all of the Ops used by the PyMC distributions that I want to generalize. Before beginning work on the actual issue, I began exploring Aesara, reading a lot about it from Aesara documentation and attempting to create a custom Op, which can be found here . I began to investigate various PyMC distributions, and I am grateful to my Mentor, who has always assisted and guided me at every step of the way. With the help of my Mentor, I discovered that the Cholesky decomposition is something I should tackle first because it affects many distributions, including MvNormal, MvStudentT, MatrixNormal... etc. Because there are a lot of things going on in the Cholesky decomposition (for example making node, infering shape, calculating grad...etc), my mentor suggested that I start by solving a simple Op, such as tril , triu . After learning a little bit about these Ops, I was able to create my first PR #1026 , which was merged into the main branch. Hooray \ud83d\ude4c\ud83e\udd73\ud83c\udf89, my first 1\ufe0f\u20e3 PR has been merged, and I am super excited and energised to solve other Ops. I began testing all other Ops with batched data and listed all of the Ops that do not support >2D data. The Ops used by the distributions are listed below, and detailed testing of these Ops can be found in this Jupyter notebook Notebook 1 , Notebook 2 . Below are the lists of Ops used by PyMC distributions MvNormal matrix_inverse solve (L_Op is left to be implemented) cholesky (dependent on solve) MvStudentT at.broadcast_arrays at.concatenate at.full at.diag at.all at.switch at.sum at.log at.dot solve_upper_triangular solve_lower_triangular aesara.tensor.gammaln at.log1p KroneckerNormal at.transpose at.sqrt at.batched_dot MatrixNormal at.full_like at.nlinalg.matrix_dot at.nlinalg.trace LKJCorr at.zeros_like at.take at.fill_diagonal at.arange at.linalg.det LKJCholeskyCov at.cumsum at.zeros at.sqrt StickBreakingWeights at.or_ at.any at.and_ at.le at. ge at.allclose at.neq at.linalg.eigh at.linalg.trace After testing all of the operations with batch data,I identified the following operations to work on: solve cholesky det eigh matrix_inverse Achived this month: Got a thorough understanding of Aesara Ops Generalized tril and triu beyond 2D arrays PR #1026 Listed out all the Ops to work on Month - 2\ufe0f\u20e3: This month's goal is to complete the Cholesky decomposition and the Solve method. I spent a lot of time experimenting with the performance of Numpy and Scipy. I created two notebooks, one for small batches of data and the other for large amounts of data. I timed Numpy and Scipy as they computed the Cholesky decomposition. We decided to use Numpy Cholesky decomposition method in Aesara after seeing the results from experimets. The detailed code implementation and tests of solve methodcan be found in PR #1060 . After submitting a PR for solve method, we received feedback from the Aesara developers and decided to use Scipy solve method and Cholesky decomposition instead of NumPy because SciPy supports many more parameters. So I spent all of my time generalising all of the Scipy methods using the NumPy vectorization technique. Work completed this month: Tested Numpy vs Scipy performance to solve cholesky decomposition - Notebook - 1 , Notebook - 2 Implemented the Numpy Solve method in Aesara, Code . Implemented the NumPy Cholesky method, Code Implemented NumPy determinant method, Code implemented NumPy eigh method, Code Used NumPy vectorization to generalise Scipy's solve, Cholesky, determinant, and eigh method, Code Create tests for all new features and improve existing tests to test Ops with batched data. Month - 3\ufe0f\u20e3: We planned to work on generalising the PyMC distribution beyond 2D data this month in the GSoC proposal. Though our project requires the resolution of a few Ops in order to function, there are numerous other Ops that must be generalised in order to work with batched data in Apsara. As a result, we decide to work on issue #695 . This new Op allows Aesara to support batched data for all Ops, which not only solves our problem but also adds a new feature to Apsara. @brandonwillard has already outlined a PR #757 for Blockwise Op, and my task is to add the grad method to this Op and get it to merge to the main branch after all of the implementation is complete. Aside from Aesara-related tasks, I was able to devote some time to PyMC distribution development. StickBreakingWeights was the first distribution I chose because it does not require any Aesara Ops to function. Thank you to my mentor for explaining how PyMC works in detail. After observing the current implementation, I was able to devise a solution, and this was my first merged PR #6042 to PyMC that allow for batched alpha in StickBreakingWeights. Work done this month: Started working on Blockwise Op Got the PR #6042 that allow for batched alpha in StickBreakingWeights . Contributions \u2692 During this GSoC period, I worked on some issues and submitted Pull Requests; some of them were merged, while others are still open and I am working on them. A summary of them is provided below. Generalize tril and triu beyond 2D arrays PR #1026 Add Op to solve batched linear matrix equation PR #1060 Generalize aesara.tensor.linalg.cholesky beyond 2D arrays PR #1012 allow for batched alpha in StickBreakingWeights PR #6042 Implemented the Numpy Solve method in Aesara, Code . Implemented the NumPy Cholesky method, Code Implemented NumPy determinant method, Code implemented NumPy eigh method, Code Used NumPy vectorization to generalise Scipy's solve, Cholesky, determinant, and eigh method, Code Notebook/Gists Created \ud83d\udcdd Whatever experiments I conduct to help my learning, I polish them and share them using Jupyter Notebook. Here are all of the experiments I conducted this summer. Cholesky - Numpy vs Scipy for Large Array, Source Cholesky - Numpy vs Scipy for Small Array, Source Creating a new Op in Aesara, Source Creating new Ops - Python implementation, Source Experimenting with numpy solve, Source Performance Comparison for Solve method - Numpy vs Scipy, Source StickBreakingWeights - Experiment, Source Testing Cholesky Vectorization, Source Testing Ops with Nd data, Source Testing Tril and Triu for batch data, Source Working Tril for 3D Data, Source Numpy Solve Example, Source Future Goals \ud83d\udccc Some future tasks I would like to work upon Complete implementation Blockwise Op Generalize below PyMC distributions: MvNormal MvStudentT KroneckerNormal MatrixNormal Conclusion \ud83d\udc8c It was a fantastic experience to contribute to open source. I learned a lot of new things. I made some wonderful friends, including @larryshamalama , @danhphan , @kunalghosh , @hassanconor , @5hv5hvnk and @nicospinu . Volunteered in building the PyMCon 2022 website . I'd like to thank my mentors Sayam Kumar and Ricardo Vieira for their unwavering support throughout this journey. I'm having a great time with the PyMC community. Next, I'd like to thank the @numfocus community for making this opportunity available through Google Summer of Code. Thank you for being a part of this wonderful summer. With \ud83d\udc97, Purna Chandra Mansingh","title":"Google Summer of Code'22 Highlights with PyMC"},{"location":"gsoc/work-summary/#google-summer-of-code22-highlights-with-pymc","text":"This post is intended to summarise the work completed during the GSoC coding period.","title":"Google Summer of Code'22 Highlights with PyMC"},{"location":"gsoc/work-summary/#about-the-project","text":"Several multivariate distributions in PyMC, such as MvNormal, MvStudentT, and others, are constrained to working with 2D inputs and do not function with arbitrarily batched dimensions. The project's goal was to improve multivariate distribution support, making it possible to work with batched data (>2D) in a vectorized manner.","title":"About the project \ud83d\udea9"},{"location":"gsoc/work-summary/#community-bounding-period","text":"This was a super interesting period. I got to know about many PyMC core developers through slack. Due to my university exam I was quite occupied but I managed to spent some time learning about the basics of Bayesian statistics, RandomVariable, Aesara. I took part in PyMC Developer Hackathon which gave me opprtunity of meet with PyMC core developer in video call and learned a lot of things about PyMC. I started working on some good first issue and by the help of PyMC team I was able to merger the PR #5806 The most difficult part for me was understanding the Aesara, how the symbolic variale works and how to implement a new Ops.","title":"Community Bounding Period \ud83e\udd1d"},{"location":"gsoc/work-summary/#month-1","text":"The coding period began on June 13, and my goal for this period was to list all of the Ops used by the PyMC distributions that I want to generalize. Before beginning work on the actual issue, I began exploring Aesara, reading a lot about it from Aesara documentation and attempting to create a custom Op, which can be found here . I began to investigate various PyMC distributions, and I am grateful to my Mentor, who has always assisted and guided me at every step of the way. With the help of my Mentor, I discovered that the Cholesky decomposition is something I should tackle first because it affects many distributions, including MvNormal, MvStudentT, MatrixNormal... etc. Because there are a lot of things going on in the Cholesky decomposition (for example making node, infering shape, calculating grad...etc), my mentor suggested that I start by solving a simple Op, such as tril , triu . After learning a little bit about these Ops, I was able to create my first PR #1026 , which was merged into the main branch. Hooray \ud83d\ude4c\ud83e\udd73\ud83c\udf89, my first 1\ufe0f\u20e3 PR has been merged, and I am super excited and energised to solve other Ops. I began testing all other Ops with batched data and listed all of the Ops that do not support >2D data. The Ops used by the distributions are listed below, and detailed testing of these Ops can be found in this Jupyter notebook Notebook 1 , Notebook 2 .","title":"Month - 1\ufe0f\u20e3:"},{"location":"gsoc/work-summary/#below-are-the-lists-of-ops-used-by-pymc-distributions","text":"MvNormal matrix_inverse solve (L_Op is left to be implemented) cholesky (dependent on solve) MvStudentT at.broadcast_arrays at.concatenate at.full at.diag at.all at.switch at.sum at.log at.dot solve_upper_triangular solve_lower_triangular aesara.tensor.gammaln at.log1p KroneckerNormal at.transpose at.sqrt at.batched_dot MatrixNormal at.full_like at.nlinalg.matrix_dot at.nlinalg.trace LKJCorr at.zeros_like at.take at.fill_diagonal at.arange at.linalg.det LKJCholeskyCov at.cumsum at.zeros at.sqrt StickBreakingWeights at.or_ at.any at.and_ at.le at. ge at.allclose at.neq at.linalg.eigh at.linalg.trace After testing all of the operations with batch data,I identified the following operations to work on: solve cholesky det eigh matrix_inverse","title":"Below are the lists of Ops used by PyMC distributions"},{"location":"gsoc/work-summary/#achived-this-month","text":"Got a thorough understanding of Aesara Ops Generalized tril and triu beyond 2D arrays PR #1026 Listed out all the Ops to work on","title":"Achived this month:"},{"location":"gsoc/work-summary/#month-2","text":"This month's goal is to complete the Cholesky decomposition and the Solve method. I spent a lot of time experimenting with the performance of Numpy and Scipy. I created two notebooks, one for small batches of data and the other for large amounts of data. I timed Numpy and Scipy as they computed the Cholesky decomposition. We decided to use Numpy Cholesky decomposition method in Aesara after seeing the results from experimets. The detailed code implementation and tests of solve methodcan be found in PR #1060 . After submitting a PR for solve method, we received feedback from the Aesara developers and decided to use Scipy solve method and Cholesky decomposition instead of NumPy because SciPy supports many more parameters. So I spent all of my time generalising all of the Scipy methods using the NumPy vectorization technique.","title":"Month - 2\ufe0f\u20e3:"},{"location":"gsoc/work-summary/#work-completed-this-month","text":"Tested Numpy vs Scipy performance to solve cholesky decomposition - Notebook - 1 , Notebook - 2 Implemented the Numpy Solve method in Aesara, Code . Implemented the NumPy Cholesky method, Code Implemented NumPy determinant method, Code implemented NumPy eigh method, Code Used NumPy vectorization to generalise Scipy's solve, Cholesky, determinant, and eigh method, Code Create tests for all new features and improve existing tests to test Ops with batched data.","title":"Work completed this month:"},{"location":"gsoc/work-summary/#month-3","text":"We planned to work on generalising the PyMC distribution beyond 2D data this month in the GSoC proposal. Though our project requires the resolution of a few Ops in order to function, there are numerous other Ops that must be generalised in order to work with batched data in Apsara. As a result, we decide to work on issue #695 . This new Op allows Aesara to support batched data for all Ops, which not only solves our problem but also adds a new feature to Apsara. @brandonwillard has already outlined a PR #757 for Blockwise Op, and my task is to add the grad method to this Op and get it to merge to the main branch after all of the implementation is complete. Aside from Aesara-related tasks, I was able to devote some time to PyMC distribution development. StickBreakingWeights was the first distribution I chose because it does not require any Aesara Ops to function. Thank you to my mentor for explaining how PyMC works in detail. After observing the current implementation, I was able to devise a solution, and this was my first merged PR #6042 to PyMC that allow for batched alpha in StickBreakingWeights.","title":"Month - 3\ufe0f\u20e3:"},{"location":"gsoc/work-summary/#work-done-this-month","text":"Started working on Blockwise Op Got the PR #6042 that allow for batched alpha in StickBreakingWeights .","title":"Work done this month:"},{"location":"gsoc/work-summary/#contributions","text":"During this GSoC period, I worked on some issues and submitted Pull Requests; some of them were merged, while others are still open and I am working on them. A summary of them is provided below. Generalize tril and triu beyond 2D arrays PR #1026 Add Op to solve batched linear matrix equation PR #1060 Generalize aesara.tensor.linalg.cholesky beyond 2D arrays PR #1012 allow for batched alpha in StickBreakingWeights PR #6042 Implemented the Numpy Solve method in Aesara, Code . Implemented the NumPy Cholesky method, Code Implemented NumPy determinant method, Code implemented NumPy eigh method, Code Used NumPy vectorization to generalise Scipy's solve, Cholesky, determinant, and eigh method, Code","title":"Contributions \u2692"},{"location":"gsoc/work-summary/#notebookgists-created","text":"Whatever experiments I conduct to help my learning, I polish them and share them using Jupyter Notebook. Here are all of the experiments I conducted this summer. Cholesky - Numpy vs Scipy for Large Array, Source Cholesky - Numpy vs Scipy for Small Array, Source Creating a new Op in Aesara, Source Creating new Ops - Python implementation, Source Experimenting with numpy solve, Source Performance Comparison for Solve method - Numpy vs Scipy, Source StickBreakingWeights - Experiment, Source Testing Cholesky Vectorization, Source Testing Ops with Nd data, Source Testing Tril and Triu for batch data, Source Working Tril for 3D Data, Source Numpy Solve Example, Source","title":"Notebook/Gists Created \ud83d\udcdd"},{"location":"gsoc/work-summary/#future-goals","text":"Some future tasks I would like to work upon Complete implementation Blockwise Op Generalize below PyMC distributions: MvNormal MvStudentT KroneckerNormal MatrixNormal","title":"Future Goals \ud83d\udccc"},{"location":"gsoc/work-summary/#conclusion","text":"It was a fantastic experience to contribute to open source. I learned a lot of new things. I made some wonderful friends, including @larryshamalama , @danhphan , @kunalghosh , @hassanconor , @5hv5hvnk and @nicospinu . Volunteered in building the PyMCon 2022 website . I'd like to thank my mentors Sayam Kumar and Ricardo Vieira for their unwavering support throughout this journey. I'm having a great time with the PyMC community. Next, I'd like to thank the @numfocus community for making this opportunity available through Google Summer of Code. Thank you for being a part of this wonderful summer. With \ud83d\udc97, Purna Chandra Mansingh","title":"Conclusion \ud83d\udc8c"}]}